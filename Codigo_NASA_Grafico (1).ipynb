{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Conecta o Colab ao Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "f1GXVzJRWihe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xarray rioxarray netCDF4 matplotlib\n"
      ],
      "metadata": {
        "id": "F9zfIiP4W1Hj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- CÉLULA 3 -----------------\n",
        "# Definindo os caminhos para os arquivos no Google Drive\n",
        "path_pace = '/content/drive/My Drive/projeto_tubaroes/PACE_OCI.clorofila_fitoplancton.nc'\n",
        "path_modis = '/content/drive/My Drive/projeto_tubaroes/AQUA_MODIS_Temperature.nc'\n",
        "path_swot = '/content/drive/My Drive/projeto_tubaroes/SWOT_WindWave.nc'\n",
        "\n",
        "# Imprimindo para confirmar que os caminhos estão corretos\n",
        "print(\"Arquivo PACE:\", path_pace)\n",
        "print(\"Arquivo MODIS:\", path_modis)\n",
        "print(\"Arquivo SWOT:\", path_swot)\n"
      ],
      "metadata": {
        "id": "aXcnA2VXXPw3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- CÉLULA 4 ----------------\n",
        "# Abrindo os arquivos netCDF com caminhos corretos\n",
        "\n",
        "import xarray as xr\n",
        "import os\n",
        "\n",
        "# Caminhos corretos dos arquivos no Google Drive\n",
        "path_pace = \"/content/drive/My Drive/projetos_tubaroes/PACE_OCI.clorofila_fitoplancton.nc\"\n",
        "path_modis = \"/content/drive/My Drive/projetos_tubaroes/AQUA_MODIS_Temperature.nc\"\n",
        "path_swot = \"/content/drive/My Drive/projetos_tubaroes/SWOT_WindWave.nc\"\n",
        "\n",
        "# Função para abrir dataset de forma segura\n",
        "def abrir_dataset(path):\n",
        "    if os.path.exists(path):\n",
        "        ds = xr.open_dataset(path)\n",
        "        print(f\"Arquivo carregado com sucesso: {os.path.basename(path)}\")\n",
        "        return ds\n",
        "    else:\n",
        "        print(f\"Erro: Arquivo não encontrado em {path}\")\n",
        "        return None\n",
        "\n",
        "# Abrindo os arquivos\n",
        "ds_pace = abrir_dataset(path_pace)\n",
        "ds_modis = abrir_dataset(path_modis)\n",
        "ds_swot = abrir_dataset(path_swot)\n",
        "\n",
        "# Exibir informações básicas de cada dataset\n",
        "if ds_pace is not None:\n",
        "    print(\"\\n--- Dados PACE (Clorofila-a) ---\")\n",
        "    print(ds_pace)\n",
        "\n",
        "if ds_modis is not None:\n",
        "    print(\"\\n--- Dados MODIS (Temperatura do mar) ---\")\n",
        "    print(ds_modis)\n",
        "\n",
        "if ds_swot is not None:\n",
        "    print(\"\\n--- Dados SWOT (Altura da superfície do mar e ondas) ---\")\n",
        "    print(ds_swot)\n"
      ],
      "metadata": {
        "id": "XLmIVVS5cKgj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "id": "bhJ286jidAA3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Célula 5 corrigida com Cartopy --------\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "def plot_global_map(data, lats, lons, title, cmap='viridis', vmin=None, vmax=None):\n",
        "    \"\"\"\n",
        "    Plota dados globais sobre mapa usando Cartopy\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(14,7))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "\n",
        "    # Contornos da Terra\n",
        "    ax.add_feature(cfeature.LAND, zorder=0, edgecolor='black')\n",
        "    ax.add_feature(cfeature.OCEAN, zorder=0)\n",
        "    ax.add_feature(cfeature.COASTLINE)\n",
        "    ax.gridlines(draw_labels=True)\n",
        "\n",
        "    # Transformar meshgrid em 2D para pcolormesh\n",
        "    mesh = ax.pcolormesh(lons, lats, data, cmap=cmap, vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree())\n",
        "    plt.colorbar(mesh, ax=ax, orientation='vertical', label=title)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# -------- PACE – Clorofila-a --------\n",
        "chlor_a = ds_pace['chlor_a'].values\n",
        "lats_pace = ds_pace['lat'].values\n",
        "lons_pace = ds_pace['lon'].values\n",
        "lon2d_pace, lat2d_pace = np.meshgrid(lons_pace, lats_pace)\n",
        "\n",
        "plot_global_map(chlor_a, lat2d_pace, lon2d_pace, 'Clorofila-a (mg/m³) – PACE', cmap='Greens')\n",
        "\n",
        "# -------- MODIS – Temperatura do mar --------\n",
        "sst = ds_modis['sst'].values\n",
        "lats_modis = ds_modis['lat'].values\n",
        "lons_modis = ds_modis['lon'].values\n",
        "lon2d_modis, lat2d_modis = np.meshgrid(lons_modis, lats_modis)\n",
        "\n",
        "plot_global_map(sst, lat2d_modis, lon2d_modis, 'Temperatura da Superfície do Mar (°C) – MODIS', cmap='RdYlBu_r', vmin=0, vmax=35)\n",
        "\n",
        "\n",
        "# -------- SWOT – Altura das Ondas (scatter para dados irregulares) --------\n",
        "swh = ds_swot['swh_karin'].values  # Pode ser (num_lines, num_pixels) ou (num_lines, num_sides, num_pixels)\n",
        "# Se ainda for 3D, tira média sobre 'num_sides'\n",
        "if swh.ndim == 3:\n",
        "    swh = np.mean(swh, axis=1)  # agora swh é (num_lines, num_pixels)\n",
        "\n",
        "# Achata para 1D (todos os pontos)\n",
        "swh_flat = swh.flatten()\n",
        "lats_flat = ds_swot['latitude'].values\n",
        "lons_flat = ds_swot['longitude'].values\n",
        "# Se tiver 3D, achata também\n",
        "if lats_flat.ndim == 3:\n",
        "    lats_flat = np.mean(lats_flat, axis=1).flatten()\n",
        "    lons_flat = np.mean(lons_flat, axis=1).flatten()\n",
        "else:\n",
        "    lats_flat = lats_flat.flatten()\n",
        "    lons_flat = lons_flat.flatten()\n",
        "\n",
        "# Plot usando scatter\n",
        "plt.figure(figsize=(14,7))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.add_feature(cfeature.LAND, edgecolor='black')\n",
        "ax.add_feature(cfeature.COASTLINE)\n",
        "ax.add_feature(cfeature.OCEAN)\n",
        "ax.gridlines(draw_labels=True)\n",
        "\n",
        "sc = ax.scatter(lons_flat, lats_flat, c=swh_flat, s=1, cmap='Blues', vmin=0, vmax=10, transform=ccrs.PlateCarree())\n",
        "plt.colorbar(sc, ax=ax, orientation='vertical', label='Altura das Ondas (m) – SWOT')\n",
        "plt.title('Altura das Ondas (m) – SWOT')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hZgkJovEf3MM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- CÉLULA 6 -----------------\n",
        "# Pré-processamento: regridding, rasterização do SWOT e normalização\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import os\n",
        "\n",
        "# Caminho para salvar o índice final no Drive\n",
        "saida_nc = \"/content/drive/My Drive/projetos_tubaroes/indice_tubarao.nc\"\n",
        "\n",
        "print(\"INICIANDO PRÉ-PROCESSAMENTO...\")\n",
        "\n",
        "# 1) Definir grade-alvo (usaremos a grade do PACE - 0.1° já carregada)\n",
        "lat_target = np.array(ds_pace['lat'].values)    # pode estar decrescente\n",
        "lon_target = np.array(ds_pace['lon'].values)\n",
        "\n",
        "# Ordenar centros em ordem crescente (necessário para histogram bins)\n",
        "lat_centers = np.sort(lat_target)\n",
        "lon_centers = np.sort(lon_target)\n",
        "\n",
        "# passos aproximados (assumimos grade regular)\n",
        "dlat = np.mean(np.diff(lat_centers))\n",
        "dlon = np.mean(np.diff(lon_centers))\n",
        "print(f\"Grade alvo: {len(lat_centers)} lat x {len(lon_centers)} lon  |  dlat={dlat:.4f}, dlon={dlon:.4f}\")\n",
        "\n",
        "# 2) Regriddar MODIS (SST) para a grade do PACE usando xarray.interp (mais simples)\n",
        "print(\"Reamostrando MODIS (SST) para a grade do PACE...\")\n",
        "try:\n",
        "    # alguns datasets têm lat/lon como coordenadas nomeadas 'lat' e 'lon' (verifique)\n",
        "    sst_interp = ds_modis['sst'].interp(lat=lat_centers, lon=lon_centers, method='nearest')\n",
        "    sst_grid = sst_interp.values  # shape (nlat, nlon)\n",
        "    print(\"OK: reamostragem MODIS concluída com xarray.interp.\")\n",
        "except Exception as e:\n",
        "    print(\"AVISO: reamostragem com xarray.interp falhou:\", e)\n",
        "    print(\"Tentando interpolação simples por nearest usando numpy (fallback)...\")\n",
        "    # fallback: nearest neighbour manual (pode ser lento); aqui só para robustez\n",
        "    # Criar meshgrid de coords MODIS e grade alvo e usar nearest via broadcasting (pesado)\n",
        "    # Para simplicidade: preencher com NaN e abortar (o usuário pode instalar xesmf para regridding real)\n",
        "    sst_grid = np.full((len(lat_centers), len(lon_centers)), np.nan)\n",
        "    print(\"Fallback criou grade vazia (recomenda-se instalar xesmf para regridding mais robusto).\")\n",
        "\n",
        "# 3) Pegando clorofila (já está na grade do PACE) — garantir alinhamento com lat_centers/ lon_centers\n",
        "print(\"Pegando clorofila (PACE) na grade alvo...\")\n",
        "chl = ds_pace['chlor_a'].values\n",
        "# Se os lat/lon do PACE estavam decrescentes, rearranjamos para lat_centers crescentes\n",
        "if not np.all(np.diff(ds_pace['lat'].values) > 0):\n",
        "    # ds_pace lat estava decrescente — reorder\n",
        "    order_lat = np.argsort(ds_pace['lat'].values)\n",
        "    chl = chl[order_lat, :]\n",
        "    print(\"Reordenado eixo latitude do PACE para ordem crescente.\")\n",
        "\n",
        "# 4) Rasterizar os pontos SWOT (swh_karin) para a grade alvo usando bincount / histogram2d\n",
        "print(\"Rasterizando SWOT (swh) na grade alvo (média por célula)...\")\n",
        "# Extrair swh e coords\n",
        "swh = ds_swot['swh_karin'].values  # possivelmente 3D (num_lines, num_sides, num_pixels) ou 2D\n",
        "lat_swot = ds_swot['latitude'].values\n",
        "lon_swot = ds_swot['longitude'].values\n",
        "\n",
        "# Se for 3D, reduzir o eixo 'num_sides' se existir\n",
        "if swh.ndim == 3:\n",
        "    swh = np.nanmean(swh, axis=1)       # agora (num_lines, num_pixels)\n",
        "    lat_swot = np.mean(lat_swot, axis=1)   # careful: may produce 2D\n",
        "    lon_swot = np.mean(lon_swot, axis=1)\n",
        "\n",
        "# Garantir arrays 2D -> achatar\n",
        "swh_flat = swh.flatten()\n",
        "lat_flat = lat_swot.flatten()\n",
        "lon_flat = lon_swot.flatten()\n",
        "\n",
        "# Filtrar NaNs e valores inválidos\n",
        "mask_valid = (~np.isnan(swh_flat)) & (~np.isnan(lat_flat)) & (~np.isnan(lon_flat))\n",
        "swh_flat = swh_flat[mask_valid]\n",
        "lat_flat = lat_flat[mask_valid]\n",
        "lon_flat = lon_flat[mask_valid]\n",
        "print(f\"Pontos SWOT válidos: {swh_flat.size}\")\n",
        "\n",
        "# Definir bin edges (centers -> edges)\n",
        "lat_edges = np.linspace(lat_centers[0] - dlat/2, lat_centers[-1] + dlat/2, len(lat_centers) + 1)\n",
        "lon_edges = np.linspace(lon_centers[0] - dlon/2, lon_centers[-1] + dlon/2, len(lon_centers) + 1)\n",
        "\n",
        "# histogram2d usa (x=lat, y=lon) -> retorna array shape (nlat, nlon)\n",
        "sum_hist, _, _ = np.histogram2d(lat_flat, lon_flat, bins=[lat_edges, lon_edges], weights=swh_flat)\n",
        "count_hist, _, _ = np.histogram2d(lat_flat, lon_flat, bins=[lat_edges, lon_edges])\n",
        "\n",
        "# média por célula (evitar divisão por zero)\n",
        "with np.errstate(invalid='ignore', divide='ignore'):\n",
        "    swh_grid = sum_hist / count_hist\n",
        "swh_grid[count_hist == 0] = np.nan\n",
        "print(\"Rasterização SWOT concluída.\")\n",
        "\n",
        "# 5) Agora temos 3 grids (nlat x nlon):\n",
        "#    - chl (from PACE) already aligned (chl)\n",
        "#    - sst_grid (from MODIS regridded) maybe contains NaNs if regrid failed\n",
        "#    - swh_grid (from SWOT rasterization)\n",
        "\n",
        "# Se sst_grid estiver todo NaN (fallback), substituir por valor neutro (safeguarda)\n",
        "if np.all(np.isnan(sst_grid)):\n",
        "    print(\"SST reamostrado inválido — preenchendo com NaN (atenção). Recomenda-se regridding com xesmf.\")\n",
        "else:\n",
        "    print(\"SST reamostrado presente.\")\n",
        "\n",
        "# 6) Normalização / transformação das variáveis\n",
        "print(\"Normalizando e convertendo variáveis para escala 0-1...\")\n",
        "\n",
        "# Função min-max robusta\n",
        "def minmax_norm(arr):\n",
        "    arr = np.array(arr, dtype=float)\n",
        "    mask = ~np.isnan(arr)\n",
        "    if np.any(mask):\n",
        "        amin = np.nanmin(arr)\n",
        "        amax = np.nanmax(arr)\n",
        "        if amax - amin == 0:\n",
        "            return np.zeros_like(arr)\n",
        "        out = (arr - amin) / (amax - amin)\n",
        "        out[~mask] = np.nan\n",
        "        return out\n",
        "    else:\n",
        "        return arr * np.nan\n",
        "\n",
        "chl_norm = minmax_norm(chl)\n",
        "swh_norm = minmax_norm(swh_grid)\n",
        "\n",
        "# Para SST, vamos usar uma função que dá score por proximidade a uma temperatura preferida (gaussiana)\n",
        "# (sugestão: ajuste preferred_temp e sigma conforme a espécie de tubarão)\n",
        "preferred_temp = 20.0   # °C (valor inicial sugerido)\n",
        "sigma_temp = 5.0        # spread em °C\n",
        "if np.all(np.isnan(sst_grid)):\n",
        "    sst_score = np.full_like(chl_norm, np.nan)\n",
        "else:\n",
        "    # aplicar gaussian similarity e normalizar em seguida\n",
        "    sst_score_raw = np.exp(-0.5 * ((sst_grid - preferred_temp) / sigma_temp)**2)\n",
        "    sst_score = minmax_norm(sst_score_raw)\n",
        "\n",
        "# 7) Combinar índices com pesos (α, β, γ)\n",
        "alpha, beta, gamma = 0.5, 0.3, 0.2   # pesos iniciais (sugestão: ajustar via validação)\n",
        "print(f\"Pesos usados: alpha={alpha}, beta={beta}, gamma={gamma}\")\n",
        "\n",
        "# Combinação com atenção a NaNs: média ponderada ignorando NaNs proporcionalmente\n",
        "# Calculamos soma ponderada e divisores (somatório de pesos presentes)\n",
        "weights_sum = np.zeros_like(chl_norm, dtype=float)\n",
        "weighted_sum = np.zeros_like(chl_norm, dtype=float)\n",
        "\n",
        "# chl contribution\n",
        "mask = ~np.isnan(chl_norm)\n",
        "weighted_sum[mask] += alpha * chl_norm[mask]\n",
        "weights_sum[mask] += alpha\n",
        "\n",
        "# sst contribution\n",
        "mask = ~np.isnan(sst_score)\n",
        "weighted_sum[mask] += beta * sst_score[mask]\n",
        "weights_sum[mask] += beta\n",
        "\n",
        "# swh contribution\n",
        "mask = ~np.isnan(swh_norm)\n",
        "weighted_sum[mask] += gamma * swh_norm[mask]\n",
        "weights_sum[mask] += gamma\n",
        "\n",
        "# evitar divisão por zero\n",
        "with np.errstate(invalid='ignore', divide='ignore'):\n",
        "    indice = weighted_sum / weights_sum\n",
        "indice[weights_sum == 0] = np.nan\n",
        "\n",
        "# 8) Salvar resultado em NetCDF no Drive\n",
        "print(\"Salvando índice combinado no Drive:\", saida_nc)\n",
        "ds_out = xr.Dataset(\n",
        "    {\n",
        "        \"indice_tubarao\": ((\"lat\",\"lon\"), indice)\n",
        "    },\n",
        "    coords = {\n",
        "        \"lat\": lat_centers,\n",
        "        \"lon\": lon_centers\n",
        "    }\n",
        ")\n",
        "# incluir atributos explicativos\n",
        "ds_out['indice_tubarao'].attrs['description'] = \"Índice combinado de probabilidade de forrageamento de tubarões (0-1).\"\n",
        "ds_out['indice_tubarao'].attrs['weights'] = f\"alpha={alpha},beta={beta},gamma={gamma}\"\n",
        "ds_out.attrs['notes'] = \"Índice gerado a partir de PACE chlor_a, MODIS SST (regrid) e SWOT swh (rasterized).\"\n",
        "\n",
        "# Salvar NetCDF\n",
        "try:\n",
        "    ds_out.to_netcdf(saida_nc)\n",
        "    print(\"Arquivo salvo com sucesso.\")\n",
        "except Exception as e:\n",
        "    print(\"Erro ao salvar NetCDF:\", e)\n",
        "\n",
        "# 9) Mostrar resumo final\n",
        "print(\"PRÉ-PROCESSAMENTO CONCLUÍDO. Resumo dos arrays:\")\n",
        "print(\"chl_norm:\", np.nanmin(chl_norm), np.nanmax(chl_norm))\n",
        "print(\"sst_score:\", np.nanmin(sst_score), np.nanmax(sst_score))\n",
        "print(\"swh_norm:\", np.nanmin(swh_norm), np.nanmax(swh_norm))\n",
        "print(\"indice:\", np.nanmin(indice), np.nanmax(indice))\n",
        "\n",
        "# (sugestão: se quiser melhorar a reamostragem espacial, instale e use 'xesmf' para remapeamento conservativo/interpolado)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hT-8Wcm8pdI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 7 – Visualização e salvamento do mapa final ===\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import os\n",
        "\n",
        "# Caminho do arquivo salvo anteriormente\n",
        "output_file = \"/content/drive/My Drive/projetos_tubaroes/indice_tubarao.nc\"\n",
        "\n",
        "# Carregar o dataset com o índice calculado\n",
        "ds_indice = xr.open_dataset(output_file)\n",
        "indice = ds_indice['indice_tubarao']\n",
        "lats = ds_indice['lat']\n",
        "lons = ds_indice['lon']\n",
        "\n",
        "# --- Visualização ---\n",
        "plt.figure(figsize=(12,6))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_global()\n",
        "ax.coastlines(resolution='110m', color='black', linewidth=0.8)\n",
        "ax.add_feature(cfeature.BORDERS, linestyle=':', alpha=0.5)\n",
        "ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "\n",
        "# Mostrar o mapa com colormap azul-verde-vermelho (baixo → alto)\n",
        "mesh = ax.pcolormesh(lons, lats, indice, cmap='turbo', vmin=0, vmax=1, transform=ccrs.PlateCarree())\n",
        "plt.colorbar(mesh, ax=ax, label='Probabilidade de presença de tubarões (0–1)', orientation='vertical')\n",
        "\n",
        "plt.title(\"Mapa de Probabilidade de Aparecimento de Tubarões\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Salvamento em PNG ---\n",
        "output_png = \"/content/drive/My Drive/projetos_tubaroes/mapa_tubarao.png\"\n",
        "plt.savefig(output_png, dpi=300, bbox_inches='tight')\n",
        "print(f\"✅ Mapa salvo com sucesso em: {output_png}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "meNTjsK9rdkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CÉLULA 8 – Mapa interativo com Plotly ===\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# Carregar dados (mesmo que antes)\n",
        "ds_indice = xr.open_dataset(output_file)\n",
        "indice = ds_indice['indice_tubarao'].values\n",
        "lats = ds_indice['lat'].values\n",
        "lons = ds_indice['lon'].values\n",
        "\n",
        "# Criar meshgrid para Plotly\n",
        "lon2d, lat2d = np.meshgrid(lons, lats)\n",
        "\n",
        "# Mapa interativo\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "    z=indice,\n",
        "    x=lons,\n",
        "    y=lats,\n",
        "    colorscale='Turbo',  # azul -> verde -> vermelho\n",
        "    zmin=0,\n",
        "    zmax=1,\n",
        "    colorbar=dict(title='Probabilidade de presença de tubarões (0–1)')\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Mapa Interativo de Ocorrência de Tubarões',\n",
        "    xaxis_title='Longitude',\n",
        "    yaxis_title='Latitude',\n",
        "    yaxis=dict(scaleanchor=\"x\"),  # manter proporção correta\n",
        "    width=1000,\n",
        "    height=500\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Dt6mIpYGuX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ CÉLULA 9: MAPA INTERATIVO OTIMIZADO COM COR \"TURBO\" ------------------\n",
        "\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import folium\n",
        "from folium import CircleMarker\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# --- Parâmetros ---\n",
        "nc_path = '/content/drive/My Drive/projetos_tubaroes/indice_tubarao.nc'\n",
        "map_save_path = '/content/drive/My Drive/projetos_tubaroes/mapa_interativo_tubarao.html'\n",
        "threshold = 0.05  # filtra pontos muito baixos para não sobrecarregar o mapa\n",
        "max_points = 50000  # limite de pontos para performance\n",
        "\n",
        "# --- Carregar dados ---\n",
        "ds = xr.open_dataset(nc_path)\n",
        "indice_tubarao = ds['indice_tubarao']  # variável correta\n",
        "\n",
        "# --- Selecionar pontos acima do limiar ---\n",
        "lats_idx, lons_idx = np.where(indice_tubarao.values > threshold)\n",
        "valores = indice_tubarao.values[lats_idx, lons_idx]\n",
        "\n",
        "# --- Reduzir quantidade de pontos se necessário ---\n",
        "if len(valores) > max_points:\n",
        "    np.random.seed(42)\n",
        "    selected_idx = np.random.choice(len(valores), max_points, replace=False)\n",
        "    lats_idx = lats_idx[selected_idx]\n",
        "    lons_idx = lons_idx[selected_idx]\n",
        "    valores = valores[selected_idx]\n",
        "\n",
        "# --- Criar mapa centralizado no globo ---\n",
        "m = folium.Map(location=[0, 0], zoom_start=2, tiles='CartoDB positron')\n",
        "\n",
        "# --- Função para converter valor em cor usando Turbo ---\n",
        "turbo_cmap = cm.get_cmap('turbo')  # azul -> vermelho\n",
        "def valor_para_cor(val):\n",
        "    rgba = turbo_cmap(val)  # retorna RGBA 0-1\n",
        "    return f'#{int(rgba[0]*255):02x}{int(rgba[1]*255):02x}{int(rgba[2]*255):02x}'\n",
        "\n",
        "# --- Adicionar pontos ao mapa ---\n",
        "for lat_i, lon_i, val in zip(lats_idx, lons_idx, valores):\n",
        "    CircleMarker(\n",
        "        location=[float(indice_tubarao.lat.values[lat_i]), float(indice_tubarao.lon.values[lon_i])],\n",
        "        radius=3,\n",
        "        fill=True,\n",
        "        fill_opacity=0.7,\n",
        "        color=None,\n",
        "        fill_color=valor_para_cor(val)\n",
        "    ).add_to(m)\n",
        "\n",
        "# --- Salvar mapa interativo ---\n",
        "m.save(map_save_path)\n",
        "print(f\"Mapa interativo salvo em: {map_save_path}\")\n"
      ],
      "metadata": {
        "id": "g3LwlfjjQ4dL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}